# -*- coding: utf-8 -*-
"""Untitled13.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1V8qoBpxx0h_aG-OobuREAaRb1sNrU4GM
"""

# Specify the path to your .zip file
zip_file_path = '/content/AS_New_heart_sound.zip'  # Update with the actual file path

# Specify the target directory where you want to extract the contents
target_directory = '/content/'  # Update with the desired directory path

# Unzip the file
import zipfile
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(target_directory)

# List the extracted files (optional)
import os
extracted_files = os.listdir(target_directory)
extracted_files

import os
import librosa
import numpy as np
import matplotlib.pyplot as plt
from scipy.signal import welch
from IPython.display import Audio, display
import librosa.display
import scipy.signal
import scipy.io.wavfile

baseFolder = '/content/AS_New_heart_sound'
def find_onset_offset(audio_file):
    audio, sr = librosa.load(audio_file)
    onset_frames = librosa.onset.onset_detect(y=audio, sr=sr)
    onset_times = librosa.frames_to_time(onset_frames, sr=sr)
    offset_times = onset_times[1:] + (onset_times[1] - onset_times[0])

    return onset_times, offset_times

def find_frequency_range(audio_file):
    audio, sr = librosa.load(audio_file)
    stft = librosa.stft(audio)
    frequencies = np.abs(librosa.fft_frequencies(sr=sr))

    min_frequency = np.min(frequencies)
    max_frequency = np.max(frequencies)

    return min_frequency, max_frequency

def extract_features(audio_file):
    audio, sr = librosa.load(audio_file)
    mel_spectrogram = librosa.feature.melspectrogram(y=audio, sr=sr)
    mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13)
    zero_crossing_rate = np.mean(librosa.feature.zero_crossing_rate(audio))
    return mel_spectrogram, mfccs, zero_crossing_rate, audio, sr

def play_audio(audio_file, autoplay=False):
    audio_widget = Audio(data=audio_file, autoplay=autoplay)
    display(audio_widget)

# def classify_heart_sound(audio_file):
#     mel_spectrogram, mfccs, zero_crossing_rate, audio, sr = extract_features(audio_file)

#     # Calculate the power spectral density (PSD)
#     f, psd = welch(audio, sr, nperseg=1024)

#     # Define frequency ranges for S1 and S2
#     s1_frequency_range = (20, 150)  # Adjust these ranges based on your data
#     s2_frequency_range = (150, 400)

#     # Integrate PSD within the frequency ranges
#     psd_s1 = np.trapz(psd[(f >= s1_frequency_range[0]) & (f <= s1_frequency_range[1])])
#     psd_s2 = np.trapz(psd[(f >= s2_frequency_range[0]) & (f <= s2_frequency_range[1])])

#     # Compare the integrated PSDs to classify as S1 or S2
#     if psd_s1 > psd_s2:
#         heart_sound_type = "S1"
#     else:
#         heart_sound_type = "S2"

#     # Print classification results
#     print(f"Heart Sound Type: {heart_sound_type}")
#     print(f"Zero Crossing Rate: {zero_crossing_rate}")

#     return heart_sound_type


def classify_heart_sound(audio_file):
    mel_spectrogram, mfccs, zero_crossing_rate, audio, sr = extract_features(audio_file)

    # Calculate the power spectral density (PSD)
    f, psd = welch(audio, sr, nperseg=1024)

    # Define frequency ranges for S1, S2, S3, and S4
    s1_frequency_range = (20, 150)
    s2_frequency_range = (150, 400)
    s3_frequency_range = (10, 40)  # Adjust these ranges based on your data
    s4_frequency_range = (40, 80)

    # Integrate PSD within the frequency ranges
    psd_s1 = np.trapz(psd[(f >= s1_frequency_range[0]) & (f <= s1_frequency_range[1])])
    psd_s2 = np.trapz(psd[(f >= s2_frequency_range[0]) & (f <= s2_frequency_range[1])])
    psd_s3 = np.trapz(psd[(f >= s3_frequency_range[0]) & (f <= s3_frequency_range[1])])
    psd_s4 = np.trapz(psd[(f >= s4_frequency_range[0]) & (f <= s4_frequency_range[1])])

    # Compare the integrated PSDs to classify as S1, S2, S3, or S4
    classification = {
        "S1": psd_s1,
        "S2": psd_s2,
        "S3": psd_s3,
        "S4": psd_s4
    }

    # Determine the class with the highest PSD
    heart_sound_type = max(classification, key=classification.get)

    # Print classification results
    print(f"Heart Sound Type: {heart_sound_type}")
    print(f"Zero Crossing Rate: {zero_crossing_rate}")

    return heart_sound_type

for root, dirs, files in os.walk(baseFolder):
    for file in files:
        if file.endswith(".wav"):
            audio_file = os.path.join(root, file)
            onset_times, offset_times = find_onset_offset(audio_file)

            # print(f"Audio File: {audio_file}")
            for i, (onset, offset) in enumerate(zip(onset_times, offset_times), start=1):
                print(f"Event {i}: Onset Time = {onset:.2f} sec, Offset Time = {offset:.2f} sec")
            print("\n")

            print(f"Audio File: {audio_file}")
            min_frequency, max_frequency = find_frequency_range(audio_file)

            print(f"Min Frequency: {min_frequency} Hz")
            print(f"Max Frequency: {max_frequency} Hz")

            # Call the classify_heart_sound function and retrieve the sample rate (sr)
            heart_sound_type = classify_heart_sound(audio_file)

            # Play the audio with the option to autoplay
            play_audio(audio_file, autoplay=False)  # Set autoplay to True if needed
            mel_spectrogram, mfccs, zero_crossing_rate,audio,sr = extract_features(audio_file)

            plt.figure(figsize=(10, 6))
            plt.subplot(3, 1, 1)
            librosa.display.specshow(librosa.power_to_db(mel_spectrogram, ref=np.max), y_axis='mel', x_axis='time')
            plt.title('Mel-spectrogram')

            plt.subplot(3, 1, 2)
            librosa.display.specshow(mfccs, x_axis='time')
            plt.title('MFCCs')

            # plt.subplot(3, 1, 3)
            # heart_sound_type = classify_heart_sound(audio_file)
            # print(f"Heart Sound Type: {heart_sound_type}")
            # print(f"Zero Crossing Rate: {zero_crossing_rate}")
            plt.tight_layout()
            plt.show()